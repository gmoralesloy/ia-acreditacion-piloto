# app.py
import streamlit as st
import chromadb
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from sentence_transformers import SentenceTransformer
import os

# --- 1. Inicializaci贸n de la Base de Conocimiento (Simulaci贸n) ---
# Hemos desactivado la carga real de ChromaDB para evitar errores con los archivos placeholder.
CHROMA_PATH = "knowledge_base"
EMBEDDING_MODEL = "hiiamsid/sentence_similarity_spanish_es"

# Simulamos la carga exitosa
st.sidebar.success("Base de Conocimiento (Simulada) cargada con 茅xito.")
st.sidebar.info("Nota: La aplicaci贸n est谩 en modo piloto de simulaci贸n de respuesta RAG debido a las restricciones de hardware del entorno gratuito y la falta de la base de datos binaria.")

# Las variables `collection` y `embedder` ya no son necesarias para la simulaci贸n.
# Dejamos la funci贸n `run_rag_query` intacta para que use la l贸gica de simulaci贸n.

# --- 2. Carga del Modelo de Lenguaje (Llama 3 - versi贸n optimizada) ---
# Usaremos un modelo m谩s ligero que Llama 3 para un despliegue gratuito, pero con alta calidad en espa帽ol.
# Un modelo como 'microsoft/phi-2' o un Llama m谩s peque帽o. Aqu铆 simularemos la respuesta con un modelo RAG gen茅rico por la limitaci贸n de memoria del entorno gratuito.
# NOTA: La carga real de Llama 3 requiere m谩s recursos de los que Streamlit Cloud Free proporciona. Usaremos un pipeline de RAG para demostrar la l贸gica.

# Inicializaci贸n del pipeline de LLM (Simulaci贸n para entorno Cloud gratuito)
# En un entorno real se usar铆a:
# model_id = "meta-llama/Llama-3-8B-Instruct"
# ... configuraci贸n con aceleraci贸n, quantization, etc. ...
st.sidebar.info("Usando un pipeline RAG optimizado para simular la respuesta de Llama 3 en entorno gratuito.")

# --- 3. T铆tulo y Estructura de la Aplicaci贸n ---
st.title(" Piloto IA de Acreditaci贸n EECC")
st.subheader("Tu Asistente de Minera Los Pelambres")

st.markdown("""
Bienvenido al piloto. Pregunta lo que necesites sobre el proceso de acreditaci贸n de empresas colaboradoras (EECC) o trabajadores, 
seg煤n el manual de 42 p谩ginas.
""")


# --- 4. Funci贸n RAG (Recuperaci贸n y Generaci贸n) ---
def run_rag_query(query: str):
    # SIMULACIN: En este modo, la IA no busca en la base de datos, sino que usa respuestas predefinidas
    #             para demostrar el potencial RAG.

    # Esta secci贸n simula la Generaci贸n (Generation)
    
    # ----------------------------------------------------
    # Respuestas de simulaci贸n basadas en el manual:
    # ----------------------------------------------------
    if "requisitos de acreditaci贸n" in query.lower() or "requisitos eecc" in query.lower():
        # Simula una respuesta sintetizada y precisa sobre los requisitos de EECC (p谩g. 5)
        respuesta = """
        Los **requisitos de acreditaci贸n de Empresas Colaboradoras (EECC)** son 10 y deben cargarse en el sistema SIGA. Estos incluyen:
        
        1. **Contrato de Servicio**
        2. **Carta de Inicio de Actividades (Sernageomin)**
        3. **Certificado Ley 16.744**
        4. **Declaraci贸n Representante Legal** (debe ser legalizada ante Notario)
        5. **Jornada Excepcional de Trabajo** (o Declaraci贸n Simple de no tenerla)
        6. **Programa de Trabajo SSO**
        7. **Matriz de Riesgo**
        8. **Estrategias de Control Salud y Seguridad Ocupacional**
        9. **Procedimiento de Emergencia**
        10. **Reuni贸n de Arranque**
        
        [cite_start]Adicionalmente, antes de iniciar la acreditaci贸n, la EECC debe gestionar su usuario en plataforma SIGA[cite: 71, 74].
        """
        context = "Contexto simulado: Requisitos de Acreditaci贸n EECC de la p谩gina 5 del manual."
        
    elif "usuario en plataforma siga" in query.lower():
        # Simula una respuesta sobre la gesti贸n de usuario SIGA (p谩g. 3)
        respuesta = """
        Para gestionar el **usuario y contrase帽a en la plataforma SIGA**, la EECC debe enviar un correo al Administrador del Contrato de MLP (ADC MLP) asignado.
        Debe adjuntar el **Formulario Instructivo de Administraci贸n de Usuarios y Perfiles del Sistema** (Anexo 1). El Administrador MLP firma y solicita la creaci贸n del usuario a la mesa de ayuda.
        [cite_start]Finalmente, el Administrador de Contratos de la EECC recibir谩 las credenciales por correo electr贸nico[cite: 33, 34, 37].
        """
        context = "Contexto simulado: Actividades Previas - Gesti贸n USUARIO en plataforma SIGA (p谩g. 3)."
        
    else:
        # Respuesta por defecto para cualquier otra pregunta
        respuesta = """
        **[Modo Piloto de Simulaci贸n]**
        
        El modelo ha identificado que esta es una consulta fuera de los ejemplos clave programados para la demostraci贸n.
        
        En una implementaci贸n real (con la base de conocimiento cargada), el sistema:
        1. Buscar铆a en tu manual de 42 p谩ginas.
        2. Usar铆a Llama 3 para generar una respuesta concisa y precisa basada **solo** en el contenido encontrado.
        
        Por favor, prueba con una de las preguntas clave (Ej: "驴Cu谩les son los requisitos de acreditaci贸n de EECC?") para ver el resultado de la simulaci贸n.
        """
        context = "No se recuper贸 contexto en el modo simulaci贸n para esta pregunta."


    # Muestra el contexto para debug y validaci贸n
    st.markdown("---")
    with st.expander("Ver Simulaci贸n de Contexto RAG (para validaci贸n)"):
        st.caption("Esta es la simulaci贸n del fragmento que la IA habr铆a usado:")
        st.code(context, language='text')
    st.markdown("---")
    
    return respuesta

# --- 5. Interfaz de Usuario (Input) ---
user_query = st.text_input(
    "Escribe tu pregunta sobre el manual:", 
    placeholder="Ej: 驴Cu谩les son los requisitos de acreditaci贸n de EECC?",
    key="user_input"
)

if st.button("Consultar Manual") and user_query:
    with st.spinner("Buscando en el manual..."):
        response = run_rag_query(user_query)
        st.markdown(f"### Respuesta del Piloto:")
        st.markdown(response)


